<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on 静心明志</title>
    <link>https://ottsion.github.io/tags/ml/</link>
    <description>Recent content in ML on 静心明志</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Feb 2020 09:39:04 +0800</lastBuildDate>
    
	<atom:link href="https://ottsion.github.io/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>EM算法理论部分</title>
      <link>https://ottsion.github.io/2020/em/</link>
      <pubDate>Wed, 19 Feb 2020 09:39:04 +0800</pubDate>
      
      <guid>https://ottsion.github.io/2020/em/</guid>
      <description>EM算法  最大期望算法（ Expectation-maximization algorithm ），是在概率模型中寻找出参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐型变量。
 一、EM要解决的问题 首先要明确的是极大似然估计解决的是单个变量的预估问题，而当这个待预测变量又同时依赖于另一个隐藏变量时，则需要使用EM进行求解。
这里需要掌握贝叶斯公式、极大似然预估这两个知识点：
1.1 贝叶斯公式 $p(w|x)=\frac{p(x|w)p(w)}{p(x)}$
其中$p(w)$为先验概率，表示每种类别分布的概率，$p(x|w)$为条件概率，表示在属于w前提下x发生的概率；$p(w|x)$为后验概率，表示x发生的前提下它属于w的概率，有了这个后验概率我们就可以对样本进行分类，后验概率越大，说明属于该类别的可能性越高。
这里常用：$p(w_i|x)=\frac{p(x|w_i)p(w_i)}{p(x)}=\frac{p(x|w_i)p(w_i)}{\sum_{j=0}^J{p(w_j)p(x|w_j)}}$ ，主要是进行了拆分，通过先验知识预测后验概率，这里$p(w_i)$以及$p(x|w_i)$概率已知。
1.2 极大似然估计 很多时候我们只有部分数据，但是要预测出该数据的概率分布，怎么做呢？就是利用已知的样本，反推最有可能（概率最大）导致这样数据样本结果的参数值。
假如我们有样本集：$D={{x_1, x_2,&amp;hellip;,x_N}}$ , 假定该样本数据服从概率$p(X|\theta)$ ，那么可以预想在该分布下生成$x_1$的概率为$p(x_1|\theta)$，生成$x_2$的概率为$p(x_2|\theta)$，以此类推，那么生成这个序列D的总体可能性为：
$p(D|\theta)=\prod_{i=1}^n{p(x_i|\theta)}$
当该概率取得最大值的时候也就是该序列D最有可能产生的时候，那么我们的目标就是寻求使得$p(D|\theta)$最大的$\theta$ ，可以看出整个公式中只有一个$\theta$未知，而我们要求最大最小值，正适合直接寻找梯度为0的位置的方法。
由于概率都是小于1的值，太多的连乘会导致结果太小甚至越界，所以我们使用log函数来放大数值结果，整体求解过程如下：
$\widehat{\theta}=argmax_{\theta}l(\theta)=argmax_{\theta}\prod_{i=1}^{N}p(x_i|\theta)$
取对数后： $\widehat{\theta}=argmax_{\theta}ln(l(\theta))=argmax_{\theta}\sum_{i=1}^{N}p(x_i|\theta)$
在似然函数满足连续可微的条件下极大似然估计量：
$\frac{dl(\theta)}{d(\theta)}=0$ ==&amp;gt; $\frac{dlnl(\theta)}{d\theta}=0$ 通过解决该方程获得$\theta$的估值。
1.3 Jensen不等式 假设$f(x)$为凸函数，X是随机变量，那么：$E[f(X)]\geq f(E[X])$ , 通俗的说法是函数的期望大于等于期望的函数。
二、EM算法的原理 如果说极大似然估计只是对一个数据分布的预测，那么当有其他的隐藏变量$z$的时候，如果使用$\frac{dl(\theta,z)}{d(\theta)}=0$ 那么通过解方程是没办法把未知的$\theta$和$z$一次求出来的，那么可以换个思路，我们先假定一个$\theta$然后求$z$，再根据这个$z$反求最优的$\theta$，通过这样来回求解直至最终收敛，形成最终的$\theta$和$z$。
可能会比较疑惑哪来的$z$，举个例子来说，我们抛硬币，原来只有一个硬币，所以我直接认为该硬币正面朝上概率为$p(\theta)$即可，但是现在有多个硬币，那么需要先知道是抛了哪个硬币，然后再乘以该硬币正面朝上的概率才是结果，此处便是有一个隐含变量$z$存在（哪个硬币，这个具体来说又可以解释为按一个概率分布$p(z)$取得该硬币）。
此时，问题的描述由$l(\theta)=\prod_{i=1}^n{p(x_i|\theta)}$ 变为了$l(\theta)=\prod_{i=1}^n{p(x_i|\theta,z)}$
那么根据全概率公式$p(B)=\sum_{i=1}^{n}p(A_i)p(B|A_i)$ 可得：
$l(\theta)=\prod_{i=1}^n{p(x_i|\theta,z)}=\prod_{i=1}^{n}\sum_{Z}p_{\theta}(z)p(x_i|z)$
两边取对数：
$lnl(\theta)=\sum_{i=1}^{n}ln\sum_{Z}p_{\theta}(z)p(x_i|z)$
我们的目标是使得$lnl(\theta)$极大似然估计值最大，这样才越能表达出当前已知序列的概率，而当我们预先设定一个$\theta=\theta_{n-1}$ 的时候（此处$\theta_{n-1}为一个假定的确定值，只是为了说明\theta更新是由第n-1个到第n个$），$lnl(\theta)$其实是一个只包含了$z$变量的函数，我们要做的是找出在该情况下使得$lnl(\theta)$最大的$z$，这时候这个$z$是基于$\theta_{n-1}$下最优的$z$，下一步就是利用这个局部最优的$z$反求在这个$z$下更优的$\theta_n$，这里要使得这个$\theta_n$ 比$\theta_{n-1}$更好，那就说明在$\theta_n$下$lnl(\theta_n)$ 比$lnl(\theta_{n-1})$更大，也就是：
$lnl(\theta_n)-lnl(\theta_{n-1})&amp;gt;0$
$lnl(\theta_n)-lnl(\theta_{n-1})=\sum_{i=1}^{n}ln\sum_{Z}p_{\theta_n}(z)p(x_i|z)-\sum_{i=1}^{n}ln\sum_{Z}p_{\theta_{n-1}}(z)p(x_i|z)$
其中由于$\theta_{n-1}$由于是常数项，可以直接将$z$省略：
$=\sum_{i=1}^{n}[ln\sum_{Z}p_{\theta_n}(z)p(x_i|z)-lnp_{\theta_{n-1}}(x_i)]$
其中可以拆解一下：
$Q1=ln\sum_{Z}p_{\theta_n}(z)p(x_i|z)=ln\sum_{z}p_{\theta_{n-1}}(z|x_i)\frac{p(x_i|z)p_{\theta_n}(z)}{p_{\theta_{n-1}}(z|x_i)}$
这里把$p_{\theta_n}(x_i)$当作x，则$\sum_{z}p_{\theta_{n-1}}(z|x_i)\frac{p(x_i|z)p_{\theta_n}(z)}{p_{\theta_{n-1}}(z|x_i)}$就是$E[x]$ ，根据jensen不等式：
$Q1=ln\sum_{z}p_{\theta_{n-1}}(z|x_i)\frac{p(x_i|z)p_{\theta_n}(z)}{p_{\theta_{n-1}}(z|x_i)}\geq \sum_{z}p_{\theta_{n-1}}(z|x_i)ln\frac{p(x_i|z)p_{\theta_n}(z)}{p(z|x_i)}$
$Q2=lnp_{\theta_{n-1}}(x_i)=lnp_{\theta_{n-1}}(x_i)\times\sum_{Z}p_{\theta_{n-1}}(z|x_i)$ 此项后部分其实和为1，它与前项无关
$Q2=\sum_{z}p_{\theta_{n-1}}(z|x_i)lnp_{\theta_{n-1}}(x_i)$</description>
    </item>
    
    <item>
      <title>推荐算法</title>
      <link>https://ottsion.github.io/2017/2017-05-11-recommendation-algorithm/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-recommendation-algorithm/</guid>
      <description>推荐算法 目前，主要的推荐方法包括：基于内容的推荐、协同过滤推荐、基于关联规则的推荐、基于效用的推荐、基于知识的推荐和组合推荐。
基于内容的推荐
基于内容的推荐（Content-based Recommendation）是信息过滤技术的延续与发展，它是建立在项目的内容信息上作出推荐的，而不需要依据用户对项目的评价意见，更多地需要用机器学习的方法从关于内容的特征描述的事例中得到用户的兴趣资料。在基于内容的推荐系统中，项目或对象是通过相关的特征的属性来定义，系统基于用户评价对象的特征，学习用户的兴趣，考察用户资料与待预测项目的相匹配程度。用户的资料模型取决于所用学习方法，常用的有决策树、神经网络和基于向量的表示方法等。 基于内容的用户资料是需要有用户的历史数据，用户资料模型可能随着用户的偏好改变而发生变化。
优点
基于内容推荐方法的优点是： 1）不需要其它用户的数据，没有冷开始问题和稀疏问题。 2）能为具有特殊兴趣爱好的用户进行推荐。 3）能推荐新的或不是很流行的项目，没有新项目问题。 4）通过列出推荐项目的内容特征，可以解释为什么推荐那些项目。 5）已有比较好的技术，如关于分类学习方面的技术已相当成熟。
缺点
缺点是要求内容能容易抽取成有意义的特征，要求特征内容有良好的结构性，并且用户的口味必须能够用内容特征形式来表达，不能显式地得到其它用户的判断情况。
协同过滤推荐
协同过滤推荐（Collaborative Filtering Recommendation）技术是推荐系统中应用最早和最为成功的技术之一。它一般采用最近邻技术，利用用户的历史喜好信息计算用户之间的距离，然后利用目标用户的最近邻居用户对商品评价的加权评价值来预测目标用户对特定商品的喜好程度，系统从而根据这一喜好程度来对目标用户进行推荐。 协同过滤最大优点是对推荐对象没有特殊的要求，能处理非结构化的复杂对象，如音乐、电影。 协同过滤是基于这样的假设：**为一用户找到他真正感兴趣的内容的好方法是首先找到与此用户有相似兴趣的其他用户，然后将他们感兴趣的内容推荐给此用户。**其基本思想非常易于理解，在日常生活中，我们往往会利用好朋友的推荐来进行一些选择。协同过滤正是把这一思想运用到电子商务推荐系统中来，基于其他用户对某一内容的评价来向目标用户进行推荐。
基于协同过滤的推荐系统可以说是从用户的角度来进行相应推荐的，而且是自动的，即用户获得的推荐是系统从购买模式或浏览行为等隐式获得的，不需要用户努力地找到适合自己兴趣的推荐信息，如填写一些调查表格等。
优点
和基于内容的过滤方法相比，协同过滤具有如下的优点： 1） 能够过滤难以进行机器自动内容分析的信息，如艺术品，音乐等。 2） 共享其他人的经验，避免了内容分析的不完全和不精确，并且能够基于一些复杂的，难以表述的概念（如信息质量、个人品味）进行过滤。 3） 有推荐新信息的能力。可以发现内容上完全不相似的信息，用户对推荐信息的内容事先是预料不到的。这也是协同过滤和基于内容的过滤一个较大的差别，基于内容的过滤推荐很多都是用户本来就熟悉的内容，而协同过滤可以发现用户潜在的但自己尚未发现的兴趣偏好。 4） 能够有效的使用其他相似用户的反馈信息，较少用户的反馈量，加快个性化学习的速度。
缺点
虽然协同过滤作为一种典型的推荐技术有其相当的应用，但协同过滤仍有许多的问题需要解决。最典型的问题有稀疏问题（Sparsity）和可扩展问题（Scalability）。
基于关联规则的推荐
基于关联规则的推荐（Association Rule-based Recommendation）是**以关联规则为基础，把已购商品作为规则头，规则体为推荐对象。****关联规则挖掘可以发现不同商品在销售过程中的相关性，在零售业中已经得到了成功的应用。关联规则就是在一个交易数据库中统计购买了商品集X的交易中有多大比例的交易同时购买了商品集Y，其直观的意义就是用户在 买某些商品的时候有多大倾向去购买另外一些商品。比如购买牛奶的同时很多人会同时购买面包。
商品之间的关联规则可以分为空间关联和时间关联两种，时间关联又可以分为周期关系和顺序关联两种。
空间关联
空间关联，也就是在同一个时间（同一次购买）里，对消费者经常一起购买的商品进行分析，这也是所谓“购物篮分析”的主要支撑技术。 最常见的空间关联规则挖掘技术，是所谓的“支持-置信”分析。以消费者在超市购买商品为例，如果把每一个消费者的一次购买看作一个事件，考虑从商品X到商品Y的关联规则，支持度是指在所有事件中同时购买商品X和商品Y的比例，置信度则是在所有购买了商品X的事件中也购买商品Y的比例[1]。如果支持度和置信度都超过了相应的阈值，则从X到Y的规则被认为是有效的。
时间关联
顺序关联
顺序关联是指购买了商品X的消费者，倾向于在一个特定的时间间隔后购买商品Y。 更严格地说，如果商品X和商品Y之间存在很强的时间关联性，则所有购买过X和Y的消费者购买X和Y的间隔时间的分布具有一个比较窄而高的峰值。
周期关联
周期关联和空间关联与顺序时间关联不同，不是两个商品之间的关联，而是同一个商品在被同一个消费者购买时在购买时间上的周期性。
关联规则算法的第一步关联规则的发现最为关键且最耗时，是算法的瓶颈，但可以离线进行。其次，商品名称的同义性问题也是关联规则的一个难点。
基于效用的推荐
基于效用的推荐（Utility-based Recommendation）是**建立在对用户使用项目的效用情况上计算的，其核心问题是怎么样为每一个用户去创建一个效用函数，因此，用户资料模型很大程度上是由系统所采用的效用函数决定的。**基于效用推荐的好处是它能把非产品的属性，如提供商的可靠性（Vendor Reliability）和产品的可得性（Product Availability）等考虑到效用计算中。
基于知识的推荐
基于知识的推荐（Knowledge-based Recommendation）在某种程度是可以看成是一种推理（Inference）技术，它不是建立在用户需要和偏好基础上推荐的。基于知识的方法因它们所用的功能知识不同而有明显区别。**效用知识（Functional Knowledge）是一种关于一个项目如何满足某一特定用户的知识，因此能解释需要和推荐的关系，**所以用户资料可以是任何能支持推理的知识结构，它可以是用户已经规范化的查询，也可以是一个更详细的用户需要的表示。
组合推荐
由于各种推荐方法都有优缺点，所以在实际中，组合推荐（Hybrid Recommendation）经常被采用。**研究和应用最多的是内容推荐和协同过滤推荐的组合。最简单的做法就是分别用基于内容的方法和协同过滤推荐方法去产生一个推荐预测结果，然后用某方法组合其结果。**尽管从理论上有很多种推荐组合方法，但在某一具体问题中并不见得都有效，组合推荐一个最重要原则就是通过组合后要能避免或弥补各自推荐技术的弱点。
组合方式
在组合方式上，有研究人员提出了七种组合思路： 1）加权（Weight）：加权多种推荐技术结果。 2）变换（Switch）：根据问题背景和实际情况或要求决定变换采用不同的推荐技术。 3）混合（Mixed）：同时采用多种推荐技术给出多种推荐结果为用户提供参考。 4）特征组合（Feature combination）：组合来自不同推荐数据源的特征被另一种推荐算法所采用。 5）层叠（Cascade）：先用一种推荐技术产生一种粗糙的推荐结果，第二种推荐技术在此推荐结果的基础上进一步作出更精确的推荐。 6）特征扩充（Feature augmentation）：一种技术产生附加的特征信息嵌入到另一种推荐技术的特征输入中。 7）元级别（Meta-level）：用一种推荐方法产生的模型作为另一种推荐方法的输入。</description>
    </item>
    
    <item>
      <title>生成模型与判别模型</title>
      <link>https://ottsion.github.io/2017/2017-05-11-shengcheng-model-panding-model/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-shengcheng-model-panding-model/</guid>
      <description>来源： 生成模型与判别模型
一、决策函数Y=f(X)或者条件概率分布P(Y|X)
 监督学习的任务就是从数据中学习一个模型（也叫分类器），应用这一模型，对给定的输入X预测相应的输出Y。这个模型的一般形式为决策函数Y=f(X)或者条件概率分布P(Y|X)。
** 决策函数Y=f(X)：**你输入一个X，它就输出一个Y，这个Y与一个阈值比较，根据比较结果判定X属于哪个类别。例如两类（w1和w2）分类问题，如果Y大于阈值，X就属于类w1，如果小于阈值就属于类w2。这样就得到了该X对应的类别了。
** 条件概率分布P(Y|X)：**你输入一个X，它通过比较它属于所有类的概率，然后输出概率最大的那个作为该X对应的类别。例如：如果P(w1|X)大于P(w2|X)，那么我们就认为X是属于w1类的。
 所以上面两个模型都可以实现对给定的输入X预测相应的输出Y的功能。实际上通过条件概率分布P(Y|X)进行预测也是隐含着表达成决策函数Y=f(X)的形式的。例如也是两类w1和w2，那么我们求得了P(w1|X)和P(w2|X)，那么实际上判别函数就可以表示为Y= P(w1|X)/P(w2|X)，如果Y大于1或者某个阈值，那么X就属于类w1，如果小于阈值就属于类w2。而同样，很神奇的一件事是，实际上决策函数Y=f(X)也是隐含着使用P(Y|X)的。因为一般决策函数Y=f(X)是通过学习算法使你的预测和训练数据之间的误差平方最小化，而贝叶斯告诉我们，虽然它没有显式的运用贝叶斯或者以某种形式计算概率，但它实际上也是在隐含的输出极大似然假设（MAP假设）。也就是说学习器的任务是在所有假设模型有相等的先验概率条件下，输出极大似然假设。
 所以呢，分类器的设计就是在给定训练数据的基础上估计其概率模型P(Y|X)。如果可以估计出来，那么就可以分类了。但是一般来说，概率模型是比较难估计的。给一堆数给你，特别是数不多的时候，你一般很难找到这些数满足什么规律吧。那能否不依赖概率模型直接设计分类器呢？事实上，分类器就是一个决策函数（或决策面），如果能够从要解决的问题和训练样本出发直接求出判别函数，就不用估计概率模型了，这就是决策函数Y=f(X)的伟大使命了。例如支持向量机，我已经知道它的决策函数（分类面）是线性的了，也就是可以表示成Y=f(X)=WX+b的形式，那么我们通过训练样本来学习得到W和b的值就可以得到Y=f(X)了。还有一种更直接的分类方法，它不用事先设计分类器，而是只确定分类原则，根据已知样本（训练样本）直接对未知样本进行分类。包括近邻法，它不会在进行具体的预测之前求出概率模型P(Y|X)或者决策函数Y=f(X)，而是在真正预测的时候，将X与训练数据的各类的Xi比较，和哪些比较相似，就判断它X也属于Xi对应的类。
 实际上，说了那么多，也不知道自己表达清楚了没有。那我们是谈生成模型和判别模型，上面到底啰嗦了那么多到底有啥阴谋啊？呵呵，往下说就知道了。
 二、生成方法和判别方法
 监督学习方法又分生成方法（Generative approach）和判别方法（Discriminative approach），所学到的模型分别称为生成模型（Generative Model）和判别模型（Discriminative Model）。咱们先谈判别方法，因为它和前面说的都差不多，比较容易明白。
** 判别方法：**由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。典型的判别模型包括k近邻，感知级，决策树，支持向量机等。
** 生成方法：**由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)。基本思想是首先建立样本的联合概率概率密度模型P(X,Y)，然后再得到后验概率P(Y|X)，再利用它进行分类，就像上面说的那样。注意了哦，这里是先求出P(X,Y)才得到P(Y|X)的，然后这个过程还得先求出P(X)。P(X)就是你的训练数据的概率分布。哎，刚才说了，需要你的数据样本非常多的时候，你得到的P(X)才能很好的描述你数据真正的分布。例如你投硬币，你试了100次，得到正面的次数和你的试验次数的比可能是3/10，然后你直觉告诉你，可能不对，然后你再试了500次，哎，这次正面的次数和你的试验次数的比可能就变成4/10，这时候你半信半疑，不相信上帝还有一个手，所以你再试200000次，这时候正面的次数和你的试验次数的比（就可以当成是正面的概率了）就变成5/10了。这时候，你就觉得很靠谱了，觉得自己就是那个上帝了。呵呵，真啰嗦，还差点离题了。
 还有一个问题就是，在机器学习领域有个约定俗成的说法是：不要去学那些对这个任务没用的东西。例如，对于一个分类任务：对一个给定的输入x，将它划分到一个类y中。那么，如果我们用生成模型：p(x,y)=p(y|x).p(x)
 那么，我们就需要去对p(x)建模，但这增加了我们的工作量，这让我们很不爽（除了上面说的那个估计得到P(X)可能不太准确外）。实际上，因为数据的稀疏性，导致我们都是被强迫地使用弱独立性假设去对p(x)建模的，所以就产生了局限性。所以我们更趋向于直观的使用判别模型去分类。
 这样的方法之所以称为生成方法，是因为模型表示了给定输入X产生输出Y的生成关系。用于随机生成的观察值建模，特别是在给定某些隐藏参数情况下。典型的生成模型有：朴素贝叶斯和隐马尔科夫模型等。
 三、生成模型和判别模型的优缺点
 在监督学习中，两种方法各有优缺点，适合于不同条件的学习问题。
** 生成方法的特点：**上面说到，生成方法学习联合概率密度分布P(X,Y)，所以就可以从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。但它不关心到底划分各类的那个分类边界在哪。生成方法可以还原出联合概率分布P(Y|X)，而判别方法不能。生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快的收敛于真实模型，当存在隐变量时，仍可以用生成方法学习。此时判别方法就不能用。
** 判别方法的特点：**判别方法直接学习的是决策函数Y=f(X)或者条件概率分布P(Y|X)。不能反映训练数据本身的特性。但它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。直接面对预测，往往学习的准确率更高。由于直接学习P(Y|X)或P(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。
 四、生成模型和判别模型的联系
 由生成模型可以得到判别模型，但由判别模型得不到生成模型。
 五、再形象点可以吗
 例如我们有一个输入数据x，然后我们想将它分类为标签y。（迎面走过来一个人，你告诉我这个是男的还是女的）
 生成模型学习联合概率分布p(x,y)，而判别模型学习条件概率分布p(y|x)。
下面是个简单的例子：
例如我们有以下(x,y)形式的数据：(1,0), (1,0), (2,0), (2, 1)
那么p(x,y)是：
 y=0 y=1
 &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;
 x=1 | 1/2 0</description>
    </item>
    
  </channel>
</rss>