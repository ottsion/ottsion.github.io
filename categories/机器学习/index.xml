<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on 静心明志</title>
    <link>https://ottsion.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on 静心明志</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 May 2017 23:59:59 +0000</lastBuildDate>
    
	<atom:link href="https://ottsion.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>adaboost算法</title>
      <link>https://ottsion.github.io/2017/2017-05-11-adaboost/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-adaboost/</guid>
      <description>链接:
1. 线性回归总结 2. 正则化 3. 逻辑回归 4. Boosting 5. Adaboost算法
转自：原地址 提升方法（boosting）是一种常用的统计学习方法，应用广泛且有效。在分类问题中，它通过改变训练样本的权重，学习多个分类器，并将这些分类器进行线性组合，提高分类的性能。 本章首先介绍提升方法的思路和代表性的提升算法AdaBoost，然后通过训练误差分析探讨AdaBoost为什么能够提高学习精度，并且从前向分布加法模型的角度解释AdaBoost，最后叙述提升方法更具体的事例——提升术（boosting tree）。AdaBoost算法是1995年由Freund和Schapire提出的，提升树是2000年由Friedman等人提出的。（开头几段内容来自《统计学习方法》） Adaboost算法基本原理
提升方法的基本思路 提升方法是基于这样一种思想：对于一个复杂任务来说，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断好。通俗点说，就是”三个臭皮匠顶个诸葛亮”。 Leslie Valiant首先提出了“强可学习（strongly learnable）”和”弱可学习（weakly learnable）”的概念，并且指出：在概率近似正确（probably approximately correct, PAC）学习的框架中，一个概念（一个类），如果存在一个多项式的学习算法能够学习它，并且正确率很高，那么就称这个概念是强可学习的，如果正确率不高，仅仅比随即猜测略好，那么就称这个概念是弱可学习的。2010年的图灵奖给了L. Valiant，以表彰他的PAC理论 。非常有趣的是Schapire后来证明强可学习与弱可学习是等价的，也就是说，在PAC学习的框架下，一个概念是强可学习的充要条件是这个概念是可学习的。 这样一来，问题便成为，在学习中，如果已经发现了“弱学习算法”，那么能否将它提升（boost）为”强学习算法”。大家知道，发现弱学习算法通常比发现强学习算法容易得多。那么如何具体实施提升，便成为开发提升方法时所要解决的问题。关于提升方法的研究很多，有很多算法被提出。最具代表性的是AdaBoost算法（Adaptive Boosting Algorithm），可以说，AdaBoost实现了PAC的理想。 对于分类问题而言，给定一个训练数据，求一个比较粗糙的分类器（即弱分类器）要比求一个精确的分类器（即强分类器）容易得多。提升方法就是从弱学习算法出发，反复学习，得到一系列弱分类器，然后组合这些弱分类器，构成一个强分类器。大多数的提升方法都是改变训练数据的概率分布（训练数据中的各个数据点的权值分布），调用弱学习算法得到一个弱分类器，再改变训练数据的概率分布，再调用弱学习算法得到一个弱分类器，如此反复，得到一系列弱分类器。 这样，对于提升方法来说，有两个问题需要回答：一是在每一轮如何如何改变训练数据的概率分布；而是如何将多个弱分类器组合成一个强分类器。 关于第一个问题，AdaBoost的做法是，提高那些被前几轮弱分类器线性组成的分类器错误分类的的样本的权值。这样一来，那些没有得到正确分类的数据，由于权值加大而受到后一轮的弱分类器的更大关注。于是，分类问题被一系列的弱分类器”分而治之”。至于第二个问题，AdaBoost采取加权多数表决的方法。具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。 AdaBoost的巧妙之处就在于它将这些想法自然而然且有效地实现在一种算法里。
AdaBoost算法 输入：训练数据集T={(x1,y1),(x2,y2),…,(xN,yN)}，其中xi∈X⊆Rn，表示输入数据，yi∈Y={-1,+1}，表示类别标签；弱学习算法。 输出：最终分类器G(x)。 流程： 初始化训练数据的概率分布，刚开始为均匀分布
D1=(w11,w12,…,w1N), 其中w1i= , i=1,2,..,N . Dm表示在第m轮迭代开始前，训练数据的概率分布（或权值分布），wmi表示在第i个样本的权值， 。对m=1,2,…,M，使用具有权值分布Dm的训练数据集进行学习（任意选一种模型都可以，例如朴素贝叶斯，决策树，SVM等，并且每一轮迭代都可以用不同的模型），得到一个弱分类器 计算Gm(x)在训练数据集上的分类误差率 计算弱分类器Gm(x)的系数 更新训练数据的权值分布 这里，Zm是规范化因子 这样 ，它使Dm+1称为一个概率分布。将M个基本分类器进行线性组合 得到最终分类器 对AdaBoost算法作如下说明： 步骤(1) 初始时假设训练数据集具有均匀分布，即每个训练样本在弱分类器的学习中作用相同。 步骤(2) &amp;copy; αm表示Gm(x)在最终分类器中的重要性。由式(公式 2)可知，当em ≤1/2时，αm≥0，并且αm随着em的减小而增大，即意味着误差率越小的基本分类器在最终分类器中的作用越大。 (d) 式可以写成： 由此可知，被弱分类器Gm(x)误分类的样本的权值得以扩大，而被正确分类的样本的权值得以缩小。因此误分类样本在下一轮学习中起到更大的作用。不改变所给的训练数据，而不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起不同的作用，这是AdaBoost的一个特点。 步骤(3) 这里，αm之和并不等于1。f(x)的符号决定实例x的类别，f(x)的绝对值表示分类的确信度。利用基本分类器进行线性组合得到最终分类器是AdaBoost的另一个特点。
AdaBoost的例子 例 1 给定如表 1所示训练数据。假设弱分类器由G(x)=sign(x-v)产生，其中v为常量，表示阀值。试用AdaBoost算法学习一个强分类器。 表 1 训练数据样本</description>
    </item>
    
    <item>
      <title>Boosting算法</title>
      <link>https://ottsion.github.io/2017/2017-05-11-boosting/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-boosting/</guid>
      <description>链接: 1. 线性回归总结 2. 正则化 3. 逻辑回归 4. Boosting 5. Adaboost算法
模型来源 提升算法是常用的有效的统计学习算法，属于迭代算法，它通过不断地使用一个弱学习器弥补前一个弱学习器的“不足”的过程，来串行地构造一个较强的学习器，这个强学习器能够使目标函数值足够小。从优化的角度分析，与一般的在参数空间搜索最优解的学习算法（如神经网络）类似，Boosting也是一个迭代搜索，且最优的算法，不同的是，它的搜索空间是学习器空间，或说函数空间（Function space），它的搜索方向是构造不断完善的强学习器，以达到目标函数（或说误差函数）足够小的目的。 Bagging也是一种常用的统计学习方法，两者经常放在一起对比，它们不同的是，Bagging将在Bootstrap采样得到的不同训练子集上的弱学习器的结果综合考虑，各个弱学习器的构建过程是并行的。而Boosting是通过串行地不断迭加弱学习器形成一个强学习器，是学习模型的提升过程。此外，Boosting迭代在降低训练误差的同时，使模型预测的确信度（margin）不断提高，是它获得较好泛化能力的主要原因，而Bagging主要是通过平均来降低模型的方差(variation).
example 为说明Boosting的主要过程，下面举一个简化的例子。 假设训练数据集为(x1,y1),(x2,y2),&amp;hellip;,(xn,yn)我们的任务是寻找使这个回归问题的均方误差最小的模型F(x). 如果已经有一个初始的模型f,且f(x1)=0.8,但y1=0.9 ,f(x2)=1.4,但y2=1.3 …显然f是不完美的，我们可以采用不断完善f的方式,如不断在f的基础上增加模型（如决策树）h,即：f(x)←f(x)+h(x),使f 趋于F. 我们希望： f(x1)+h(x1)=y1 ====&amp;gt; h(x1)=y1−f(x1) f(x2)+h(x2)=y2 ====&amp;gt; h(x2)=y2−f(x2) ... ====&amp;gt; ... f(xn)+h(xn)=yn ====&amp;gt; h(xn)=yn−f(xn)  然而恰好满足上式的h可能不存在，但我们总可以找到使残差yi−f(xi)变小的h. 上述过程等价于拟合如下数据集：
(x1,y1−f(x1)) (x2,y2−f(x2)) ... (xn,yn−f(xn))  上述一次叠加h的过程就是Boosting的一次迭代。要使f足够接近F一般需要多次迭代。
依据损失函数的不同具体分类有：
链接:关于AdaBoost的算法推导
Gradient Boosting 和Adaboost不同，Gradient Boosting 在迭代的时候选择梯度下降的方向来保证最后的结果最好。 损失函数用来描述模型的“靠谱”程度，假设模型没有过拟合，损失函数越大，模型的错误率越高 如果我们的模型能够让损失函数持续的下降，则说明我们的模型在不停的改进，而最好的方式就是让损失函数在其梯度方向上下降。 import numpy as np import matplotlib.pyplot as plt from sklearn import ensemble from sklearn import datasets from sklearn.</description>
    </item>
    
    <item>
      <title>决策树与随机森林</title>
      <link>https://ottsion.github.io/2017/2017-05-11-rf/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-rf/</guid>
      <description>原文 决策树是一种树形结构，其中每一个内部节点表示在一个特征（属性）上的测试，每个分支代表一个测试输出，每个叶子节点代表一种类别。 决策树学习是一种归纳学习，从一堆数据中归纳出一个学习模型出来。决策树学习采用的是自顶向下的递归学习，其基本思想是以信息熵为度量构造一棵熵值下降最快的树，树不断构建的过程也就是熵不断下降的过程。而其中节点的具体特征选择取决于哪个特征在当前节点的熵下降最快（如在构建根节点的时候，比较了年龄、长相、收入、是否公务员这些特征，发现选择年龄这一特征会导致熵下降最快，于是选择年龄作为根节点）。以此类推，到了叶子节点处的熵值即为零。至于说具体如何比较及计算熵下降的程度，稍后会给出。
决策树的优缺点 决策树算法的最大优点是：它可以自学习。在学习的过程中，不需要使用者了解过多背景知识，只需要对训练实例进行较好的标注，就能够进行学习。像之前的”是否出去玩”例子，只要给定一个表格，并且每一列（最后一列是标注列）都给定（并不需要知道每一列表示的含义），那么决策树就会自己构造出一种基于规则的决策算法。 决策树缺点：可以看出，决策树的决策过程实质上是贪心法，在每一步的时候都选择当前状态下的最优解，一直走下去。我们知道贪心法并不能保证得到的最终结果是全局最优的，这也是决策树的缺陷之一，有可能会导致过拟合的问题.
知识点补充： ## 经验熵与经验条件熵 只要给定一个随机变量P，我们就可以求得该随机变量的熵。但是实践中，我们得到的并不是真正的随机变量p，得到的只是p的若干采样，那么我们实践中得到的熵就不一定是真正的随机变量p的熵，于是，我们称实践中得到的熵为经验熵，类似地也就有了经验条件熵的概念。教科书上的表述：当熵和条件熵中的概率是由数据估计得到时，所对应的熵和条件熵分别称为经验熵和经验条件熵。
决策树的生成算法&amp;ndash;ID3、C4.5、CART 建立决策树的关键，是在当前状态下选择哪个特征（即属性）作为节点。之前已经讲过，选择节点的依据取决于哪个特征在当前节点的熵下降最快。那么给出了一堆数据，那么如何求每个特征的熵（或熵下降的程度）呢？根据不同的目标函数，决策树算法主要有三种算法：ID3、C4.5、CART。</description>
    </item>
    
    <item>
      <title>推荐算法</title>
      <link>https://ottsion.github.io/2017/2017-05-11-recommendation-algorithm/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-recommendation-algorithm/</guid>
      <description>推荐算法 目前，主要的推荐方法包括：基于内容的推荐、协同过滤推荐、基于关联规则的推荐、基于效用的推荐、基于知识的推荐和组合推荐。
基于内容的推荐
基于内容的推荐（Content-based Recommendation）是信息过滤技术的延续与发展，它是建立在项目的内容信息上作出推荐的，而不需要依据用户对项目的评价意见，更多地需要用机器学习的方法从关于内容的特征描述的事例中得到用户的兴趣资料。在基于内容的推荐系统中，项目或对象是通过相关的特征的属性来定义，系统基于用户评价对象的特征，学习用户的兴趣，考察用户资料与待预测项目的相匹配程度。用户的资料模型取决于所用学习方法，常用的有决策树、神经网络和基于向量的表示方法等。 基于内容的用户资料是需要有用户的历史数据，用户资料模型可能随着用户的偏好改变而发生变化。
优点
基于内容推荐方法的优点是： 1）不需要其它用户的数据，没有冷开始问题和稀疏问题。 2）能为具有特殊兴趣爱好的用户进行推荐。 3）能推荐新的或不是很流行的项目，没有新项目问题。 4）通过列出推荐项目的内容特征，可以解释为什么推荐那些项目。 5）已有比较好的技术，如关于分类学习方面的技术已相当成熟。
缺点
缺点是要求内容能容易抽取成有意义的特征，要求特征内容有良好的结构性，并且用户的口味必须能够用内容特征形式来表达，不能显式地得到其它用户的判断情况。
协同过滤推荐
协同过滤推荐（Collaborative Filtering Recommendation）技术是推荐系统中应用最早和最为成功的技术之一。它一般采用最近邻技术，利用用户的历史喜好信息计算用户之间的距离，然后利用目标用户的最近邻居用户对商品评价的加权评价值来预测目标用户对特定商品的喜好程度，系统从而根据这一喜好程度来对目标用户进行推荐。 协同过滤最大优点是对推荐对象没有特殊的要求，能处理非结构化的复杂对象，如音乐、电影。 协同过滤是基于这样的假设：为一用户找到他真正感兴趣的内容的好方法是首先找到与此用户有相似兴趣的其他用户，然后将他们感兴趣的内容推荐给此用户。其基本思想非常易于理解，在日常生活中，我们往往会利用好朋友的推荐来进行一些选择。协同过滤正是把这一思想运用到电子商务推荐系统中来，基于其他用户对某一内容的评价来向目标用户进行推荐。
基于协同过滤的推荐系统可以说是从用户的角度来进行相应推荐的，而且是自动的，即用户获得的推荐是系统从购买模式或浏览行为等隐式获得的，不需要用户努力地找到适合自己兴趣的推荐信息，如填写一些调查表格等。
优点
和基于内容的过滤方法相比，协同过滤具有如下的优点： 1） 能够过滤难以进行机器自动内容分析的信息，如艺术品，音乐等。 2） 共享其他人的经验，避免了内容分析的不完全和不精确，并且能够基于一些复杂的，难以表述的概念（如信息质量、个人品味）进行过滤。 3） 有推荐新信息的能力。可以发现内容上完全不相似的信息，用户对推荐信息的内容事先是预料不到的。这也是协同过滤和基于内容的过滤一个较大的差别，基于内容的过滤推荐很多都是用户本来就熟悉的内容，而协同过滤可以发现用户潜在的但自己尚未发现的兴趣偏好。 4） 能够有效的使用其他相似用户的反馈信息，较少用户的反馈量，加快个性化学习的速度。
缺点
虽然协同过滤作为一种典型的推荐技术有其相当的应用，但协同过滤仍有许多的问题需要解决。最典型的问题有稀疏问题（Sparsity）和可扩展问题（Scalability）。
基于关联规则的推荐
基于关联规则的推荐（Association Rule-based Recommendation）是以关联规则为基础，把已购商品作为规则头，规则体为推荐对象。***关联规则挖掘可以发现不同商品在销售过程中的相关性*，在零售业中已经得到了成功的应用。关联规则就是在一个交易数据库中统计购买了商品集X的交易中有多大比例的交易同时购买了商品集Y，其直观的意义就是用户在 买某些商品的时候有多大倾向去购买另外一些商品。比如购买牛奶的同时很多人会同时购买面包。
商品之间的关联规则可以分为空间关联和时间关联两种，时间关联又可以分为周期关系和顺序关联两种。
空间关联
空间关联，也就是在同一个时间（同一次购买）里，对消费者经常一起购买的商品进行分析，这也是所谓“购物篮分析”的主要支撑技术。 最常见的空间关联规则挖掘技术，是所谓的“支持-置信”分析。以消费者在超市购买商品为例，如果把每一个消费者的一次购买看作一个事件，考虑从商品X到商品Y的关联规则，支持度是指在所有事件中同时购买商品X和商品Y的比例，置信度则是在所有购买了商品X的事件中也购买商品Y的比例[1]。如果支持度和置信度都超过了相应的阈值，则从X到Y的规则被认为是有效的。
时间关联
顺序关联
顺序关联是指购买了商品X的消费者，倾向于在一个特定的时间间隔后购买商品Y。 更严格地说，如果商品X和商品Y之间存在很强的时间关联性，则所有购买过X和Y的消费者购买X和Y的间隔时间的分布具有一个比较窄而高的峰值。
周期关联
周期关联和空间关联与顺序时间关联不同，不是两个商品之间的关联，而是同一个商品在被同一个消费者购买时在购买时间上的周期性。
关联规则算法的第一步关联规则的发现最为关键且最耗时，是算法的瓶颈，但可以离线进行。其次，商品名称的同义性问题也是关联规则的一个难点。
基于效用的推荐
基于效用的推荐（Utility-based Recommendation）是建立在对用户使用项目的效用情况上计算的，其核心问题是怎么样为每一个用户去创建一个效用函数，因此，用户资料模型很大程度上是由系统所采用的效用函数决定的。基于效用推荐的好处是它能把非产品的属性，如提供商的可靠性（Vendor Reliability）和产品的可得性（Product Availability）等考虑到效用计算中。
基于知识的推荐
基于知识的推荐（Knowledge-based Recommendation）在某种程度是可以看成是一种推理（Inference）技术，它不是建立在用户需要和偏好基础上推荐的。基于知识的方法因它们所用的功能知识不同而有明显区别。效用知识（Functional Knowledge）是一种关于一个项目如何满足某一特定用户的知识，因此能解释需要和推荐的关系，所以用户资料可以是任何能支持推理的知识结构，它可以是用户已经规范化的查询，也可以是一个更详细的用户需要的表示。
组合推荐
由于各种推荐方法都有优缺点，所以在实际中，组合推荐（Hybrid Recommendation）经常被采用。研究和应用最多的是内容推荐和协同过滤推荐的组合。最简单的做法就是分别用基于内容的方法和协同过滤推荐方法去产生一个推荐预测结果，然后用某方法组合其结果。尽管从理论上有很多种推荐组合方法，但在某一具体问题中并不见得都有效，组合推荐一个最重要原则就是通过组合后要能避免或弥补各自推荐技术的弱点。
组合方式
在组合方式上，有研究人员提出了七种组合思路： 1）加权（Weight）：加权多种推荐技术结果。 2）变换（Switch）：根据问题背景和实际情况或要求决定变换采用不同的推荐技术。 3）混合（Mixed）：同时采用多种推荐技术给出多种推荐结果为用户提供参考。 4）特征组合（Feature combination）：组合来自不同推荐数据源的特征被另一种推荐算法所采用。 5）层叠（Cascade）：先用一种推荐技术产生一种粗糙的推荐结果，第二种推荐技术在此推荐结果的基础上进一步作出更精确的推荐。 6）特征扩充（Feature augmentation）：一种技术产生附加的特征信息嵌入到另一种推荐技术的特征输入中。 7）元级别（Meta-level）：用一种推荐方法产生的模型作为另一种推荐方法的输入。</description>
    </item>
    
    <item>
      <title>正则化</title>
      <link>https://ottsion.github.io/2017/2017-05-11-regularization/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-regularization/</guid>
      <description>链接: 1. 线性回归总结 2. 正则化 3. 逻辑回归 4. Boosting 5. Adaboost算法
一. 过拟合 从下图中可以看出在这三种拟合线条中一般线性拟合效果最差，只是描绘出了一种趋势，四次多项式拟合效果很完美，完全覆盖了训练集中的点。但是从实际来说数据时存在各种偏差的，肯定存在一些杂质或者误差，它在完美的拟合数据的同时意味着将这种误差也拟合在内，这种的结果是在测试集中会存在明显的差别，可能效果很差，我们需要拟合的不是误差，而是数据中的共性，存在的规律。 此时存在两种问题： 1. 如一般线回归合下发生的欠拟合：并没有很好地找到数据的规律 2. 如四次多项式回归下发生的过拟合：过多的将不需要的性质加入回归。如果我们拟合一个高阶多项式，那么这个函数能很好的拟合训练集（能拟合几乎所有的训练数据），但这也就面临函数可能太过庞大的问题，变量太多。同时如果我们没有足够的数据集（训练集）去约束这个变量过多的模型，那么就会发生过拟合。
过度拟合的问题通常发生在变量（特征）过多的时候。这种情况下训练出的方程总是能很好的拟合训练数据，也就是说，我们的代价函数可能非常接近于 0 或者就为 0。但是，这样的曲线千方百计的去拟合训练数据，这样会导致它无法泛化到新的数据样本中， 二. 处理方式 那么，如果发生了过拟合问题，我们应该如何处理？ 过多的变量（特征），同时只有非常少的训练数据，会导致出现过度拟合的问题。因此为了解决过度拟合，有以下两个办法。 1. 人工选择减少特征数目 2. 通过机器学习算法之类的算法去选取主要特征，放弃次要特征 3. 正则化：不去减少特征，而是通过优化配置参数θ去实现消除过拟合
正则化 正则化中我们将保留所有的特征变量，但是会减小特征变量的数量级（参数数值的大小θ(j)）。这个方法非常有效，当我们有很多特征变量时，其中每一个变量都能对预测产生一点影响比如我们有很多特征变量，其中每一个变量都是有用的，因此我们不希望把它们删掉，这就导致了正则化概念的发生。 在论文中常见的都聚集在：零范数、一范数、二范数、迹范数、Frobenius范数和核范数等等
L0范数与L1范数 L0范数是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0 L1范数是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）。为什么L1范数会使权值稀疏？有人可能会这样给你回答“它是L0范数的最优凸近似”。实际上，还存在一个更美的回答：任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。这说是这么说，W的L1范数是绝对值，|w|在w=0处是不可微，但这还是不够直观。这里因为我们需要和L2范数进行对比分析。 既然L0可以实现稀疏，为什么不用L0，而要用L1呢？因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。所以大家才把目光和万千宠爱转于L1范数。 OK，来个一句话总结：L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。它能实现特征的自动选择和有很好的可解释性。
L2范数 L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项||W||2最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的哦。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。为什么越小的参数说明模型越简单？我也不懂，我的理解是：限制了参数很小，实际上就限制了多项式某些分量的影响很小（看上面线性回归的模型的那个拟合的图），这样就相当于减少参数个数。其实我也不太懂，希望大家可以指点下。
这里也一句话总结下：通过L2范数，我们可以实现了对模型空间的限制，从而在一定程度上避免了过拟合。 当然，采用正则化以后之前的矩阵求系数W就可以解决： lasso回归效果（一范数）： ![lasso回归] ](http://upload-images.jianshu.io/upload_images/1070582-fc992c96c6abb03a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) Ridge回归效果（二范数）： # -*- coding: utf-8 -*- &amp;quot;&amp;quot;&amp;quot; Created on Thu May 04 20:08:49 2017 @author: SUNFC &amp;quot;&amp;quot;&amp;quot; import numpy as np import matplotlib.</description>
    </item>
    
    <item>
      <title>生成模型与判别模型</title>
      <link>https://ottsion.github.io/2017/2017-05-11-shengcheng-model-panding-model/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-shengcheng-model-panding-model/</guid>
      <description>来源： 生成模型与判别模型
一、决策函数Y=f(X)或者条件概率分布P(Y|X)
 监督学习的任务就是从数据中学习一个模型（也叫分类器），应用这一模型，对给定的输入X预测相应的输出Y。这个模型的一般形式为决策函数Y=f(X)或者条件概率分布P(Y|X)。
 决策函数Y=f(X)：你输入一个X，它就输出一个Y，这个Y与一个阈值比较，根据比较结果判定X属于哪个类别。例如两类（w1和w2）分类问题，如果Y大于阈值，X就属于类w1，如果小于阈值就属于类w2。这样就得到了该X对应的类别了。
 条件概率分布P(Y|X)：你输入一个X，它通过比较它属于所有类的概率，然后输出概率最大的那个作为该X对应的类别。例如：如果P(w1|X)大于P(w2|X)，那么我们就认为X是属于w1类的。
 所以上面两个模型都可以实现对给定的输入X预测相应的输出Y的功能。实际上通过条件概率分布P(Y|X)进行预测也是隐含着表达成决策函数Y=f(X)的形式的。例如也是两类w1和w2，那么我们求得了P(w1|X)和P(w2|X)，那么实际上判别函数就可以表示为Y= P(w1|X)/P(w2|X)，如果Y大于1或者某个阈值，那么X就属于类w1，如果小于阈值就属于类w2。而同样，很神奇的一件事是，实际上决策函数Y=f(X)也是隐含着使用P(Y|X)的。因为一般决策函数Y=f(X)是通过学习算法使你的预测和训练数据之间的误差平方最小化，而贝叶斯告诉我们，虽然它没有显式的运用贝叶斯或者以某种形式计算概率，但它实际上也是在隐含的输出极大似然假设（MAP假设）。也就是说学习器的任务是在所有假设模型有相等的先验概率条件下，输出极大似然假设。
 所以呢，分类器的设计就是在给定训练数据的基础上估计其概率模型P(Y|X)。如果可以估计出来，那么就可以分类了。但是一般来说，概率模型是比较难估计的。给一堆数给你，特别是数不多的时候，你一般很难找到这些数满足什么规律吧。那能否不依赖概率模型直接设计分类器呢？事实上，分类器就是一个决策函数（或决策面），如果能够从要解决的问题和训练样本出发直接求出判别函数，就不用估计概率模型了，这就是决策函数Y=f(X)的伟大使命了。例如支持向量机，我已经知道它的决策函数（分类面）是线性的了，也就是可以表示成Y=f(X)=WX+b的形式，那么我们通过训练样本来学习得到W和b的值就可以得到Y=f(X)了。还有一种更直接的分类方法，它不用事先设计分类器，而是只确定分类原则，根据已知样本（训练样本）直接对未知样本进行分类。包括近邻法，它不会在进行具体的预测之前求出概率模型P(Y|X)或者决策函数Y=f(X)，而是在真正预测的时候，将X与训练数据的各类的Xi比较，和哪些比较相似，就判断它X也属于Xi对应的类。
 实际上，说了那么多，也不知道自己表达清楚了没有。那我们是谈生成模型和判别模型，上面到底啰嗦了那么多到底有啥阴谋啊？呵呵，往下说就知道了。
 二、生成方法和判别方法
 监督学习方法又分生成方法（Generative approach）和判别方法（Discriminative approach），所学到的模型分别称为生成模型（Generative Model）和判别模型（Discriminative Model）。咱们先谈判别方法，因为它和前面说的都差不多，比较容易明白。
 判别方法：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。典型的判别模型包括k近邻，感知级，决策树，支持向量机等。
 生成方法：由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)。基本思想是首先建立样本的联合概率概率密度模型P(X,Y)，然后再得到后验概率P(Y|X)，再利用它进行分类，就像上面说的那样。注意了哦，这里是先求出P(X,Y)才得到P(Y|X)的，然后这个过程还得先求出P(X)。P(X)就是你的训练数据的概率分布。哎，刚才说了，需要你的数据样本非常多的时候，你得到的P(X)才能很好的描述你数据真正的分布。例如你投硬币，你试了100次，得到正面的次数和你的试验次数的比可能是3/10，然后你直觉告诉你，可能不对，然后你再试了500次，哎，这次正面的次数和你的试验次数的比可能就变成4/10，这时候你半信半疑，不相信上帝还有一个手，所以你再试200000次，这时候正面的次数和你的试验次数的比（就可以当成是正面的概率了）就变成5/10了。这时候，你就觉得很靠谱了，觉得自己就是那个上帝了。呵呵，真啰嗦，还差点离题了。
 还有一个问题就是，在机器学习领域有个约定俗成的说法是：不要去学那些对这个任务没用的东西。例如，对于一个分类任务：对一个给定的输入x，将它划分到一个类y中。那么，如果我们用生成模型：p(x,y)=p(y|x).p(x)
 那么，我们就需要去对p(x)建模，但这增加了我们的工作量，这让我们很不爽（除了上面说的那个估计得到P(X)可能不太准确外）。实际上，因为数据的稀疏性，导致我们都是被强迫地使用弱独立性假设去对p(x)建模的，所以就产生了局限性。所以我们更趋向于直观的使用判别模型去分类。
 这样的方法之所以称为生成方法，是因为模型表示了给定输入X产生输出Y的生成关系。用于随机生成的观察值建模，特别是在给定某些隐藏参数情况下。典型的生成模型有：朴素贝叶斯和隐马尔科夫模型等。
 三、生成模型和判别模型的优缺点
 在监督学习中，两种方法各有优缺点，适合于不同条件的学习问题。
 生成方法的特点：上面说到，生成方法学习联合概率密度分布P(X,Y)，所以就可以从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。但它不关心到底划分各类的那个分类边界在哪。生成方法可以还原出联合概率分布P(Y|X)，而判别方法不能。生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快的收敛于真实模型，当存在隐变量时，仍可以用生成方法学习。此时判别方法就不能用。
 判别方法的特点：判别方法直接学习的是决策函数Y=f(X)或者条件概率分布P(Y|X)。不能反映训练数据本身的特性。但它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。直接面对预测，往往学习的准确率更高。由于直接学习P(Y|X)或P(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。
 四、生成模型和判别模型的联系
 由生成模型可以得到判别模型，但由判别模型得不到生成模型。
 五、再形象点可以吗
 例如我们有一个输入数据x，然后我们想将它分类为标签y。（迎面走过来一个人，你告诉我这个是男的还是女的）
 生成模型学习联合概率分布p(x,y)，而判别模型学习条件概率分布p(y|x)。
下面是个简单的例子：
例如我们有以下(x,y)形式的数据：(1,0), (1,0), (2,0), (2, 1)
那么p(x,y)是：
 y=0 y=1
 &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;
 x=1 | 1/2 0</description>
    </item>
    
    <item>
      <title>线性回归</title>
      <link>https://ottsion.github.io/2017/2017-05-11-linear-regression/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-linear-regression/</guid>
      <description>链接: 1. 线性回归总结 2. 正则化 3. 逻辑回归 4. Boosting 5. Adaboost算法
一. 模型介绍 线性回归简而言之就是在平面中用一条直线去拟合一些点数据,在三维空间中就是用一个平面去拟合三维中的数据,而我们要做的就是寻找出一条最佳的线段或者平面去拟合数据,当然高维情况类似去寻找超平面。 初中的时候我们就学习过一元一次方程,那就是一个简单的拟合过程,只不过那个是完全可以拟合在一条线上,现在要做的是在有误差或者数据非线性排列的情况下,我们只能去尽力找出一条最佳的拟合线路:
import numpy as np import matplotlib.pyplot as plt x = np.arange(1,10,2).reshape(-1,1) y = a*2 plt.plot(x,y,&#39;r-&#39;,linewidth=2, label=u&amp;quot;线性拟合&amp;quot;) plt.plot(x,y, &#39;bo&#39;) plt.show()  import numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression x = np.arange(1,10,2).reshape(-1,1) y = a*2 + np.random.randn(5) linear_model = LinearRegression() linear_model.fit(x.reshape(-1, 1),y) y_pre = linear_model.predict(x) plt.plot(x,y_pre,&#39;r-&#39;,linewidth=2, label=u&amp;quot;线性拟合&amp;quot;) plt.plot(x,y, &#39;bo&#39;) plt.show()  定义一下一些符号表达，我们通常习惯用X=(x1,x2,&amp;hellip;,xn)T∈ℝn×p表示数据矩阵，其中xi∈ℝp表示一个p维度长的数据样本；y=(y1,y2,&amp;hellip;,yn)T∈ℝn表示数据的label，这里只考虑每个样本一类的情况。</description>
    </item>
    
    <item>
      <title>逻辑回归</title>
      <link>https://ottsion.github.io/2017/2017-05-11-logistic-regression/</link>
      <pubDate>Thu, 11 May 2017 23:59:59 +0000</pubDate>
      
      <guid>https://ottsion.github.io/2017/2017-05-11-logistic-regression/</guid>
      <description>链接: 1. 线性回归总结 2. 正则化 3. 逻辑回归 4. Boosting 5. Adaboost算法
线性回归是通过拟合来达到目的，而逻辑回归呢侧重的是探寻概率，它不去寻找拟合的超平面，而是去寻找某个数据的类别归属问题。
一. 预测函数 怎么去预测？我们知道Sigmoid函数是如上这样的，它的表现是：将数据归纳在0-1之间，那么我们能不能通过去计算出的结果去拟合这样一个概率，使之成为一种分类的依据？答案是肯定的。凡事的概率都在0和1之间，拟合了概率，就是拟合了判定条件。 二. 具体做法 我们知道线性回归是这样子的： 将Sigmoid函数加载到这个结果上，不就是将结果0-1概率化了么： 所以是这样子的：
三. 损失函数 这样一来针对已有数据那就是0/1问题，要么概率为1的数据，要么概率为0的数据：
对于我们来说概率可以简写合并成： 取其似然函数： 我们要做的是在最大似然估计就是求使 L(θ )取最大值时的θ 这里可以自己做主，我选用下面作为损失函数，要是最大似然估计最大，就要使J(θ)函数最小，通过不断的优化θ使得J函数最小，进而L函数概率最大，完成任务。 四. 求解过程 1. 梯度下降法： 2. 矩阵法： 通过依次求解A，E, θ得到最终解。（A为线性回归的θ*X）
参考： 逻辑回归 逻辑回归模型(Logistic Regression, LR)基础 - 文赛平 机器学习—逻辑回归理论简介</description>
    </item>
    
  </channel>
</rss>