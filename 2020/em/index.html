<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="Fengcai.Sun">
  
  
  
  <link rel="prev" href="https://ottsion.github.io/2020/2020_tag/" />
  
  <script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
  <link rel="canonical" href="https://ottsion.github.io/2020/em/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           EM算法理论部分 | 静心明志
       
  </title>
  <meta name="title" content="EM算法理论部分 | 静心明志">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https:\/\/ottsion.github.io"
    },
    "articleSection" : "posts",
    "name" : "EM算法理论部分",
    "headline" : "EM算法理论部分",
    "description" : "EM算法  最大期望算法（ Expectation-maximization algorithm ），是在概率模型中寻找出参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐型变量。\n 一、EM要解决的问题 首先要明确的是极大似然估计解决的是单个变量的预估问题，而当这个待预测变量又同时依赖于另一个隐藏变量时，则需要使用EM进行求解。\n这里需要掌握贝叶斯公式、极大似然预估这两个知识点：\n1.1 贝叶斯公式 $p(w|x)=\\frac{p(x|w)p(w)}{p(x)}$\n其中$p(w)$为先验概率，表示每种类别分布的概率，$p(x|w)$为条件概率，表示在属于w前提下x发生的概率；$p(w|x)$为后验概率，表示x发生的前提下它属于w的概率，有了这个后验概率我们就可以对样本进行分类，后验概率越大，说明属于该类别的可能性越高。\n这里常用：$p(w_i|x)=\\frac{p(x|w_i)p(w_i)}{p(x)}=\\frac{p(x|w_i)p(w_i)}{\\sum_{j=0}^J{p(w_j)p(x|w_j)}}$ ，主要是进行了拆分，通过先验知识预测后验概率，这里$p(w_i)$以及$p(x|w_i)$概率已知。\n1.2 极大似然估计 很多时候我们只有部分数据，但是要预测出该数据的概率分布，怎么做呢？就是利用已知的样本，反推最有可能（概率最大）导致这样数据样本结果的参数值。\n假如我们有样本集：$D={{x_1, x_2,\x26hellip;,x_N}}$ , 假定该样本数据服从概率$p(X|\\theta)$ ，那么可以预想在该分布下生成$x_1$的概率为$p(x_1|\\theta)$，生成$x_2$的概率为$p(x_2|\\theta)$，以此类推，那么生成这个序列D的总体可能性为：\n$p(D|\\theta)=\\prod_{i=1}^n{p(x_i|\\theta)}$\n当该概率取得最大值的时候也就是该序列D最有可能产生的时候，那么我们的目标就是寻求使得$p(D|\\theta)$最大的$\\theta$ ，可以看出整个公式中只有一个$\\theta$未知，而我们要求最大最小值，正适合直接寻找梯度为0的位置的方法。\n由于概率都是小于1的值，太多的连乘会导致结果太小甚至越界，所以我们使用log函数来放大数值结果，整体求解过程如下：\n$\\widehat{\\theta}=argmax_{\\theta}l(\\theta)=argmax_{\\theta}\\prod_{i=1}^{N}p(x_i|\\theta)$\n取对数后： $\\widehat{\\theta}=argmax_{\\theta}ln(l(\\theta))=argmax_{\\theta}\\sum_{i=1}^{N}p(x_i|\\theta)$\n在似然函数满足连续可微的条件下极大似然估计量：\n$\\frac{dl(\\theta)}{d(\\theta)}=0$ ==\x26gt; $\\frac{dlnl(\\theta)}{d\\theta}=0$ 通过解决该方程获得$\\theta$的估值。\n1.3 Jensen不等式 假设$f(x)$为凸函数，X是随机变量，那么：$E[f(X)]\\geq f(E[X])$ , 通俗的说法是函数的期望大于等于期望的函数。\n二、EM算法的原理 如果说极大似然估计只是对一个数据分布的预测，那么当有其他的隐藏变量$z$的时候，如果使用$\\frac{dl(\\theta,z)}{d(\\theta)}=0$ 那么通过解方程是没办法把未知的$\\theta$和$z$一次求出来的，那么可以换个思路，我们先假定一个$\\theta$然后求$z$，再根据这个$z$反求最优的$\\theta$，通过这样来回求解直至最终收敛，形成最终的$\\theta$和$z$。\n可能会比较疑惑哪来的$z$，举个例子来说，我们抛硬币，原来只有一个硬币，所以我直接认为该硬币正面朝上概率为$p(\\theta)$即可，但是现在有多个硬币，那么需要先知道是抛了哪个硬币，然后再乘以该硬币正面朝上的概率才是结果，此处便是有一个隐含变量$z$存在（哪个硬币，这个具体来说又可以解释为按一个概率分布$p(z)$取得该硬币）。\n此时，问题的描述由$l(\\theta)=\\prod_{i=1}^n{p(x_i|\\theta)}$ 变为了$l(\\theta)=\\prod_{i=1}^n{p(x_i|\\theta,z)}$\n那么根据全概率公式$p(B)=\\sum_{i=1}^{n}p(A_i)p(B|A_i)$ 可得：\n$l(\\theta)=\\prod_{i=1}^n{p(x_i|\\theta,z)}=\\prod_{i=1}^{n}\\sum_{Z}p_{\\theta}(z)p(x_i|z)$\n两边取对数：\n$lnl(\\theta)=\\sum_{i=1}^{n}ln\\sum_{Z}p_{\\theta}(z)p(x_i|z)$\n我们的目标是使得$lnl(\\theta)$极大似然估计值最大，这样才越能表达出当前已知序列的概率，而当我们预先设定一个$\\theta=\\theta_{n-1}$ 的时候（此处$\\theta_{n-1}为一个假定的确定值，只是为了说明\\theta更新是由第n-1个到第n个$），$lnl(\\theta)$其实是一个只包含了$z$变量的函数，我们要做的是找出在该情况下使得$lnl(\\theta)$最大的$z$，这时候这个$z$是基于$\\theta_{n-1}$下最优的$z$，下一步就是利用这个局部最优的$z$反求在这个$z$下更优的$\\theta_n$，这里要使得这个$\\theta_n$ 比$\\theta_{n-1}$更好，那就说明在$\\theta_n$下$lnl(\\theta_n)$ 比$lnl(\\theta_{n-1})$更大，也就是：\n$lnl(\\theta_n)-lnl(\\theta_{n-1})\x26gt;0$\n$lnl(\\theta_n)-lnl(\\theta_{n-1})=\\sum_{i=1}^{n}ln\\sum_{Z}p_{\\theta_n}(z)p(x_i|z)-\\sum_{i=1}^{n}ln\\sum_{Z}p_{\\theta_{n-1}}(z)p(x_i|z)$\n其中由于$\\theta_{n-1}$由于是常数项，可以直接将$z$省略：\n$=\\sum_{i=1}^{n}[ln\\sum_{Z}p_{\\theta_n}(z)p(x_i|z)-lnp_{\\theta_{n-1}}(x_i)]$\n其中可以拆解一下：\n$Q1=ln\\sum_{Z}p_{\\theta_n}(z)p(x_i|z)=ln\\sum_{z}p_{\\theta_{n-1}}(z|x_i)\\frac{p(x_i|z)p_{\\theta_n}(z)}{p_{\\theta_{n-1}}(z|x_i)}$\n这里把$p_{\\theta_n}(x_i)$当作x，则$\\sum_{z}p_{\\theta_{n-1}}(z|x_i)\\frac{p(x_i|z)p_{\\theta_n}(z)}{p_{\\theta_{n-1}}(z|x_i)}$就是$E[x]$ ，根据jensen不等式：\n$Q1=ln\\sum_{z}p_{\\theta_{n-1}}(z|x_i)\\frac{p(x_i|z)p_{\\theta_n}(z)}{p_{\\theta_{n-1}}(z|x_i)}\\geq \\sum_{z}p_{\\theta_{n-1}}(z|x_i)ln\\frac{p(x_i|z)p_{\\theta_n}(z)}{p(z|x_i)}$\n$Q2=lnp_{\\theta_{n-1}}(x_i)=lnp_{\\theta_{n-1}}(x_i)\\times\\sum_{Z}p_{\\theta_{n-1}}(z|x_i)$ 此项后部分其实和为1，它与前项无关\n$Q2=\\sum_{z}p_{\\theta_{n-1}}(z|x_i)lnp_{\\theta_{n-1}}(x_i)$",
    "inLanguage" : "en-us",
    "author" : "caicai",
    "creator" : "caicai",
    "publisher": "caicai",
    "accountablePerson" : "caicai",
    "copyrightHolder" : "caicai",
    "copyrightYear" : "2020",
    "datePublished": "2020-02-19 09:39:04 \x2b0800 CST",
    "dateModified" : "2020-02-19 09:39:04 \x2b0800 CST",
    "url" : "https:\/\/ottsion.github.io\/2020\/em\/",
    "wordCount" : "97",
    "keywords" : [ "ml","em", "静心明志"]
}
</script>

</head>

  




  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://ottsion.github.io">静心明志</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/about/" title=""></a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://ottsion.github.io">静心明志</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/about/" title=""></a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">EM算法理论部分</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://ottsion.github.io" rel="author">caicai</a> with ♥ 
                <span class="post-time">
                on <time datetime=2020-02-19 itemprop="datePublished">February 19, 2020</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="https://ottsion.github.io/categories/ml/"> ML </a>
                        
                </span>
        </div>
    </header>
    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          <h1 id="em算法">EM算法</h1>
<blockquote>
<p>最大期望算法（ <strong>Expectation-maximization algorithm</strong> ），是在概率模型中寻找出参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐型变量。</p>
</blockquote>
<h2 id="一em要解决的问题">一、EM要解决的问题</h2>
<p>首先要明确的是极大似然估计解决的是单个变量的预估问题，而当这个待预测变量又同时依赖于另一个隐藏变量时，则需要使用EM进行求解。</p>
<p>这里需要掌握贝叶斯公式、极大似然预估这两个知识点：</p>
<h2 id="11-贝叶斯公式">1.1 贝叶斯公式</h2>
<p>$p(w|x)=\frac{p(x|w)p(w)}{p(x)}$</p>
<p>其中$p(w)$为先验概率，表示每种类别分布的概率，$p(x|w)$为条件概率，表示在属于w前提下x发生的概率；$p(w|x)$为后验概率，表示x发生的前提下它属于w的概率，有了这个后验概率我们就可以对样本进行分类，后验概率越大，说明属于该类别的可能性越高。</p>
<p>这里常用：$p(w_i|x)=\frac{p(x|w_i)p(w_i)}{p(x)}=\frac{p(x|w_i)p(w_i)}{\sum_{j=0}^J{p(w_j)p(x|w_j)}}$  ，主要是进行了拆分，通过先验知识预测后验概率，这里$p(w_i)$以及$p(x|w_i)$概率已知。</p>
<h3 id="12-极大似然估计">1.2 极大似然估计</h3>
<p>很多时候我们只有部分数据，但是要预测出该数据的概率分布，怎么做呢？就是利用已知的样本，反推最有可能（概率最大）导致这样数据样本结果的参数值。</p>
<p>假如我们有样本集：$D={{x_1, x_2,&hellip;,x_N}}$ , 假定该样本数据服从概率$p(X|\theta)$ ，那么可以预想在该分布下生成$x_1$的概率为$p(x_1|\theta)$，生成$x_2$的概率为$p(x_2|\theta)$，以此类推，那么生成这个序列D的总体可能性为：</p>
<p>$p(D|\theta)=\prod_{i=1}^n{p(x_i|\theta)}$</p>
<p>当该概率取得最大值的时候也就是该序列D最有可能产生的时候，那么我们的目标就是寻求使得$p(D|\theta)$最大的$\theta$ ，可以看出整个公式中只有一个$\theta$未知，而我们要求最大最小值，正适合直接寻找梯度为0的位置的方法。</p>
<p>由于概率都是小于1的值，太多的连乘会导致结果太小甚至越界，所以我们使用log函数来放大数值结果，整体求解过程如下：</p>
<p>$\widehat{\theta}=argmax_{\theta}l(\theta)=argmax_{\theta}\prod_{i=1}^{N}p(x_i|\theta)$</p>
<p>取对数后： $\widehat{\theta}=argmax_{\theta}ln(l(\theta))=argmax_{\theta}\sum_{i=1}^{N}p(x_i|\theta)$</p>
<p>在似然函数满足连续可微的条件下极大似然估计量：</p>
<p>$\frac{dl(\theta)}{d(\theta)}=0$  ==&gt; $\frac{dlnl(\theta)}{d\theta}=0$ 通过解决该方程获得$\theta$的估值。</p>
<h3 id="13-jensen不等式">1.3 Jensen不等式</h3>
<p>假设$f(x)$为凸函数，X是随机变量，那么：$E[f(X)]\geq f(E[X])$ , 通俗的说法是函数的期望大于等于期望的函数。</p>
<p><img src="../../sources/Jensen.PNG" alt=""></p>
<h2 id="二em算法的原理">二、EM算法的原理</h2>
<p>如果说极大似然估计只是对一个数据分布的预测，那么当有其他的隐藏变量$z$的时候，如果使用$\frac{dl(\theta,z)}{d(\theta)}=0$ 那么通过解方程是没办法把未知的$\theta$和$z$一次求出来的，那么可以换个思路，我们先假定一个$\theta$然后求$z$，再根据这个$z$反求最优的$\theta$，通过这样来回求解直至最终收敛，形成最终的$\theta$和$z$。</p>
<p>可能会比较疑惑哪来的$z$，举个例子来说，我们抛硬币，原来只有一个硬币，所以我直接认为该硬币正面朝上概率为$p(\theta)$即可，但是现在有多个硬币，那么需要先知道是抛了哪个硬币，然后再乘以该硬币正面朝上的概率才是结果，此处便是有一个隐含变量$z$存在（哪个硬币，这个具体来说又可以解释为按一个概率分布$p(z)$取得该硬币）。</p>
<p>此时，问题的描述由$l(\theta)=\prod_{i=1}^n{p(x_i|\theta)}$ 变为了$l(\theta)=\prod_{i=1}^n{p(x_i|\theta,z)}$</p>
<p>那么根据全概率公式$p(B)=\sum_{i=1}^{n}p(A_i)p(B|A_i)$ 可得：</p>
<p>$l(\theta)=\prod_{i=1}^n{p(x_i|\theta,z)}=\prod_{i=1}^{n}\sum_{Z}p_{\theta}(z)p(x_i|z)$</p>
<p>两边取对数：</p>
<p>$lnl(\theta)=\sum_{i=1}^{n}ln\sum_{Z}p_{\theta}(z)p(x_i|z)$</p>
<p>我们的目标是使得$lnl(\theta)$极大似然估计值最大，这样才越能表达出当前已知序列的概率，而当我们预先设定一个$\theta=\theta_{n-1}$ 的时候（此处$\theta_{n-1}为一个假定的确定值，只是为了说明\theta更新是由第n-1个到第n个$），$lnl(\theta)$其实是一个只包含了$z$变量的函数，我们要做的是找出在该情况下使得$lnl(\theta)$最大的$z$，这时候这个$z$是基于$\theta_{n-1}$下最优的$z$，下一步就是利用这个局部最优的$z$反求在这个$z$下更优的$\theta_n$，这里要使得这个$\theta_n$ 比$\theta_{n-1}$更好，那就说明在$\theta_n$下$lnl(\theta_n)$ 比$lnl(\theta_{n-1})$更大，也就是：</p>
<p>$lnl(\theta_n)-lnl(\theta_{n-1})&gt;0$</p>
<p>$lnl(\theta_n)-lnl(\theta_{n-1})=\sum_{i=1}^{n}ln\sum_{Z}p_{\theta_n}(z)p(x_i|z)-\sum_{i=1}^{n}ln\sum_{Z}p_{\theta_{n-1}}(z)p(x_i|z)$</p>
<p>其中由于$\theta_{n-1}$由于是常数项，可以直接将$z$省略：</p>
<p>$=\sum_{i=1}^{n}[ln\sum_{Z}p_{\theta_n}(z)p(x_i|z)-lnp_{\theta_{n-1}}(x_i)]$</p>
<p>其中可以拆解一下：</p>
<p>$Q1=ln\sum_{Z}p_{\theta_n}(z)p(x_i|z)=ln\sum_{z}p_{\theta_{n-1}}(z|x_i)\frac{p(x_i|z)p_{\theta_n}(z)}{p_{\theta_{n-1}}(z|x_i)}$</p>
<p>这里把$p_{\theta_n}(x_i)$当作x，则$\sum_{z}p_{\theta_{n-1}}(z|x_i)\frac{p(x_i|z)p_{\theta_n}(z)}{p_{\theta_{n-1}}(z|x_i)}$就是$E[x]$ ，根据jensen不等式：</p>
<p>$Q1=ln\sum_{z}p_{\theta_{n-1}}(z|x_i)\frac{p(x_i|z)p_{\theta_n}(z)}{p_{\theta_{n-1}}(z|x_i)}\geq \sum_{z}p_{\theta_{n-1}}(z|x_i)ln\frac{p(x_i|z)p_{\theta_n}(z)}{p(z|x_i)}$</p>
<p>$Q2=lnp_{\theta_{n-1}}(x_i)=lnp_{\theta_{n-1}}(x_i)\times\sum_{Z}p_{\theta_{n-1}}(z|x_i)$   此项后部分其实和为1，它与前项无关</p>
<p>$Q2=\sum_{z}p_{\theta_{n-1}}(z|x_i)lnp_{\theta_{n-1}}(x_i)$</p>
<p>此时：</p>
<p>$lnl(\theta_n)-lnl(\theta_{n-1})\ge \sum_{i=1}^{n}[\sum_{z}p_{\theta_{n-1}}(z|x_i)ln\frac{p(x_i|z)p_{\theta_n}(z)}{p(z|x_i)}-\sum_{z}p_{\theta_{n-1}}(z|x_i)lnp_{\theta_{n-1}}(x_i)]$</p>
<p>$=\sum_{i=1}^{n}\sum_{z}p_{\theta_{n-1}}(z|x_i)[ln\frac{p(x_i|z)p_{\theta_n}(z)}{p(z|x_i)}-lnp_{\theta_{n-1}(x_i)}]$</p>
<p>$=\sum_{i=1}^{n}\sum_{z}p_{\theta_{n-1}}(z|x_i)[ln\frac{p(x_i|z)p_{\theta_n}(z)}{p(z|x_i)p_{\theta_{n-1}(x_i)}}]$</p>
<p>$=\sum_{i=1}^{n}\sum_{z}p_{\theta_{n-1}}(z|x_i)ln\frac{p_{\theta_n}(x_i,z)}{p_{\theta_{n-1}}(z,x_i)}$</p>
<p>那我们说过不断迭代优化，这里如果有更合适的$\theta$出现的话，上式应该大于0才对，也就是新的$\theta_n$应该：</p>
<p>$lnl(\theta_n)\ge \sum_{i=1}^{n}\sum_{z}p_{\theta_{n-1}}(z|x_i)ln\frac{p_{\theta_n}(x_i,z)}{p_{\theta_{n-1}}(z,x_i)}+lnl(\theta_{n-1})$</p>
<p>右边就是下边界函数，EM的目的就是要去的目标函数的最大值，也就是不断的提升这个下边界的值来进行，假定右边界为$Q(\theta_n|\theta_{n-1})$ :</p>
<p>$Q(\theta_n|\theta_{n-1})=lnl(\theta_{n-1})+\sum_{i=1}^{n}\sum_{z}p_{\theta_{n-1}}(z|x_i)ln\frac{p_{\theta_{n}}(x_i,z)}{p_{\theta_{n-1}}(z,x_i)}$</p>
<p>求解主要集中在未知函数，我们将其中常数项拆开：</p>
<p>$Q(\theta_n|\theta_{n-1})=\sum_{i=1}^{n}\sum_{z}p_{\theta_{n-1}}(z|x_i)ln{p_{\theta_n}(x_i,z)}-\sum_{i=1}^{n}\sum_{z}p_{\theta_{n-1}}(z|x_i){p_{\theta_{n-1}}(z,x_i)}+lnl(\theta_{n-1})$</p>
<p>通过上式可以发现只有第一项带有未知数$\theta_n$ 需要求解。</p>
<p>既然要使其最大化，这里同样运用斜率（导数）为0的思想： $\frac{\partial Q(\theta_n|\theta_{n-1})}{\partial \theta_n}=0$</p>
<p>求得此时取极大值时$\theta_n$ 的取值，这个值就是进入到下一步迭代是的概率分布参数值, 有了$\theta_n$之后就可以获得$Q(\theta_{n+1}|\theta_n)$，然后不断地迭代直到收敛。图示的话如下：</p>
<p><img src="../../sources/em.jpg" alt=""></p>
<h2 id="三-em应用场景">三、 EM应用场景</h2>
<p>EM算法缺陷之一：传统的EM算法对初始值敏感，聚类结果随不同的初始值而波动较大。总的来说，EM算法收敛的优劣很大程度上取决于其初始参数。</p>
<p>EM算法应用：K-means 与 高斯混合模型</p>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>Fengcai.Sun </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://ottsion.github.io/2020/em/>https://ottsion.github.io/2020/em/</span>
            </p>
            
            <span id="busuanzi_container_page_pv">
                本文总阅读量: <span id="busuanzi_value_page_pv"></span>
            </span>
             
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="https://ottsion.github.io/tags/ml/">
                    #ml</a></span>
            
            <span class="tag"><a href="https://ottsion.github.io/tags/em/">
                    #em</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="https://ottsion.github.io">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://ottsion.github.io/2020/2020_tag/" class="prev" rel="prev" title="2020 新的一年愿望"><i class="iconfont icon-left"></i>&nbsp;2020 新的一年愿望</a>
         
        
    </div>

    
    <div class="post-comment">
        
        

<div id="vcomments"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine@1.3.7/dist/Valine.min.js'></script>

<script type="text/javascript">
  new Valine({
      el: '#vcomments' ,
      appId: 'aq7KX6LvEUKuYC1FReOy9Rq8-gzGzoHsz',
      appKey: 'AJWv8xzYkd8tJ23S38zDK3TN',
      notify: 'false', 
      verify: 'false', 
      avatar:'mm', 
      placeholder: '说点什么吧...',
      visitor: 'true'
  });
</script>
    </div>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2019 - 2020</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="https://ottsion.github.io">Fengcai.Sun</a> | </span> 
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
    </div>
</footer>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>











    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  



     </div>
  </body>
</html>
