<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="Fengcai.Sun">
  
  
  
  <link rel="prev" href="https://ottsion.github.io/2017/2017-01-05-lunwen2/" />
  <link rel="next" href="https://ottsion.github.io/2017/2017-01-05-eigen-use-2/" />
  <link rel="canonical" href="https://ottsion.github.io/2017/2017-01-05-lunwen1/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           基于 Kinect 的机器人臂手系统的目标抓取[丁美昆] | 静心明志
       
  </title>
  <meta name="title" content="基于 Kinect 的机器人臂手系统的目标抓取[丁美昆] | 静心明志">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https:\/\/ottsion.github.io"
    },
    "articleSection" : "posts",
    "name" : "基于 Kinect 的机器人臂手系统的目标抓取[丁美昆]",
    "headline" : "基于 Kinect 的机器人臂手系统的目标抓取[丁美昆]",
    "description" : "星期四, 05. 一月 2017 03:13下午\n 为了实现机器人臂手系统的目标抓取, 采用 Kinect 对目标信息进行实时检测. 首先,采用张正友棋盘标定法完成对 Kinect 内外参数的标定. 其次, 利用深度信息进行深度分割, 滤 除大部分干扰背景, 再通过颜色与形状特征实现目标的识别与定位. 将识别对象的 3 维坐标通过以太网发送至机械臂控制台, 随后机械臂移动至目标位置. 最后采用变积分 PID 算法控制灵巧手接触力, 保证响应的快速性及精密性, 实现灵巧手的精细抓取. 通过设计一套完整的实验系统验证了该方法的有效性.\n 研究点 需要机器人能够快速准确地完成对环境中物体的定位与识别, 以及实现对目标物体的精细抓取. 然而, 环境的复杂性与物体的多样性给机器人自主实现物体定位与识别带来了很大的挑战, 使得非结构环境下的物体定位与识别成为机器人研究领域的热点之一\n研究情况  文献 [3] 采用双目立体视觉实现目标识别与定位. 该双目立体视觉系统主要包括摄像机标定、图像分割、立体匹配和 3 维测距 4 个模块, 其中立体匹配是双目视觉定位的最关键的一步, 实现目标区域的准确立体匹配较难, 而立体匹配的不准确将直接导致所获取的深度信息产生偏差 [4] , 同时其实时性是双目和多目定位视觉系统面临的最大挑战.  文献 [5] 采用双目立体视觉实现目标的抓取, 即在识别物体时, 采用颜色分割法将 RGB 颜色空间转换至 HSV 颜色空间, 并通过选取阈值来分割图像, 分割后的图像受背景干扰较大且噪点较多. 文献 [6] 利用Kinect 实现目标识别与定位, 其定位前采用张正友棋盘标定法标定摄像头内外参数. 在识别物体时采用基于深度信息的背景相减法, 该方法只适用于物体变动检测.",
    "inLanguage" : "en-us",
    "author" : "caicai",
    "creator" : "caicai",
    "publisher": "caicai",
    "accountablePerson" : "caicai",
    "copyrightHolder" : "caicai",
    "copyrightYear" : "2017",
    "datePublished": "2017-01-05 23:59:59 \x2b0000 \x2b0000",
    "dateModified" : "2017-01-05 23:59:59 \x2b0000 \x2b0000",
    "url" : "https:\/\/ottsion.github.io\/2017\/2017-01-05-lunwen1\/",
    "wordCount" : "1119",
    "keywords" : [ "论文", "静心明志"]
}
</script>

</head>

  




  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://ottsion.github.io">静心明志</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/about/" title=""></a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://ottsion.github.io">静心明志</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/about/" title=""></a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">基于 Kinect 的机器人臂手系统的目标抓取[丁美昆]</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://ottsion.github.io" rel="author">caicai</a> with ♥ 
                <span class="post-time">
                on <time datetime=2017-01-05 itemprop="datePublished">January 5, 2017</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="https://ottsion.github.io/categories/%E8%AE%BA%E6%96%87%E6%91%98%E8%A6%81/"> 论文摘要 </a>
                        
                </span>
        </div>
    </header>
    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          

<p>星期四, 05. 一月 2017 03:13下午</p>

<hr />

<blockquote>
<p>为了实现机器人臂手系统的目标抓取, 采用 Kinect 对目标信息进行实时检测. 首先,采用张正友棋盘标定法完成对 Kinect 内外参数的标定. 其次, 利用深度信息进行深度分割, 滤
除大部分干扰背景, 再通过颜色与形状特征实现目标的识别与定位. 将识别对象的 3 维坐标通过以太网发送至机械臂控制台, 随后机械臂移动至目标位置. 最后采用变积分 PID 算法控制灵巧手接触力, 保证响应的快速性及精密性, 实现灵巧手的精细抓取. 通过设计一套完整的实验系统验证了该方法的有效性.</p>
</blockquote>

<hr />

<h3 id="研究点">研究点</h3>

<p>需要机器人能够快速准确地完成对环境中物体的定位与识别, 以及实现对目标物体的精细抓取. 然而, 环境的复杂性与物体的多样性给机器人自主实现物体定位与识别带来了很大的挑战, 使得非结构环境下的物体定位与识别成为机器人研究领域的热点之一</p>

<h3 id="研究情况">研究情况</h3>

<ul>
<li>文献 [3] 采用双目立体视觉实现目标识别与定位. 该双目立体视觉系统主要包括摄像机标定、图像分割、立体匹配和 3 维测距 4 个模块, 其中立体匹配是双目视觉定位的最关键的一步, 实现目标区域的准确立体匹配较难, 而立体匹配的不准确将直接导致所获取的深度信息产生偏差 [4] , 同时其实时性是双目和多目定位视觉系统面临的最大挑战.

<ul>
<li>文献 [5] 采用双目立体视觉实现目标的抓取, 即在识别物体时, 采用颜色分割法将 RGB 颜色空间转换至 HSV 颜色空间, 并通过选取阈值来分割图像, 分割后的图像受背景干扰较大且噪点较多.</li>
<li>文献 [6] 利用Kinect 实现目标识别与定位, 其定位前采用张正友棋盘标定法标定摄像头内外参数. 在识别物体时采用基于深度信息的背景相减法, 该方法只适用于物体变动检测.</li>
<li>文献 [7] 利用 Kinect采集的 RGB 与深度信息, 生成点云, 并利用点云分割来实现目标物体识别. 该方法的实时性较差, 且对算法优化要求较高 [8] .</li>
</ul></li>
</ul>

<h3 id="本文核心">本文核心</h3>

<p>本系统利用 Kinect 能够提供深度信息以及 RGB 信息的特性, 简化识别过程, 实现对目标物体的 3 维定位, 并且具有较好的实时性. 在定位前, 系统采用操作简便的张正友棋盘标定法
完成 Kinect 内外参数的标定. 识别时, 先利用 Kinect 采集的深度信息进行深度分割, 滤除大部分背景干扰, 降低后期运算识别的复杂性, 然后对深度分割后的图像进行颜色分割, 最后利用形状特征滤除干扰物, 实现对目标物体的识别.</p>

<h3 id="目标识别">目标识别</h3>

<p>本系统选用大小、形状不同的果蔬作为抓取目标, 这些果蔬主要有苹果、梨、青椒、西红
柿、香蕉、橙子等. 这些果蔬的颜色特征和形状特征较为明显, 故在识别过程中先通过颜色分割再利用果蔬的形状特征, 最终实现果蔬的识别. 在颜色分割前, 考虑到存在背景干扰, 故利用深度信息滤除背景.
 1. 深度分割
 深度分割是指利用深度信息, 将不在深度范围内的彩色图像信息滤除(见式(7)), 从而减小
识别区域, 降低后期识别运算的复杂性 [14-15] .
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 15:33:26屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure>
式中,  P<sub>RGB</sub>  为图像中某点的 RGB 值, d<sub>max</sub> 为最大的深度值, d<sub>min</sub> 为最小的深度值.本系统为了实现深度分割, 将机械臂操作台固定在距离 Kinect 0.9∼1.5 m 位置(操作台宽约 0.6 m), 将操作台深度信息以外的背景彩色图像信息滤除(全部变为黑色).在深度分割后, 将操作台面内彩色信息提取出来, 从而大大降低外部环境对果蔬识别的影响, 提高后期识别计算速度, 其效果如图 3(b)所示.
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 15:34:26屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure></p>

<h3 id="颜色与形状识别">颜色与形状识别</h3>

<p>彩色图像的分割往往需要选取合适的颜色空间进行分割, 而 RGB 颜色模型是主要面向硬件的模型, 应用于彩色视频摄像机和彩色监视器 [16] . RGB 颜色空间受光源的种类、光照的强度等因素影响, 且3个分量互相关联变化, 很难确定识别 RGB 的阈值范围. 而 HSV(色调、 饱和度、亮度)模型更符合描述和解释颜色的方式, 其中色调 H(hue)反映了该颜色最接近何种可见光谱波长, 即某一种颜色; 饱和度 S(saturation)表示一种颜色相对于其纯色的比例, 即纯洁性,可用来区别颜色明暗的程度; V(value)表示色彩的明亮程度. RGB 转换到 HSV 的转换形式为
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 15:42:58屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure>
故本系统采用 HSV 颜色空间的颜色分割, 由于某些果蔬颜色比较相近(如梨和香蕉), 往往仅通过颜色分割不能很好地识别, 因此在完成颜色分割后, 需要结合果蔬的形状特征实现果蔬的识别. 采用果蔬的圆形度 R, 可以精确地区分颜色相近的不同种类的果蔬, 其计算公式为
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 15:44:21屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure>
式中, S 为果蔬的轮廓面积, L 为果蔬轮廓周长.
具体识别步骤如下.</p>

<ul>
<li>步骤 1 进行深度信息分割后的 RGB 图像往往存在噪点, 故采用平滑滤波滤除噪点.</li>
<li>步骤 2 将滤波后的彩色图像从 RGB 颜色空间转换到 HSV 颜色空间, V 通道受光线影</li>
<li>响较大, 故在 H、 S 通道选取合适的阈值进行二值化, 其具体阈值如表 1 所示. 将二值化后的图</li>
<li>像进行形态学处理, 排除孤立噪声并对目标的缺损进行适当修补.</li>
<li>步骤 3 在颜色分割后, 利用果蔬的形状特征圆形度 R(具体范围见表 1)最终确定待识别</li>
</ul>

<p>果蔬的轮廓, 其具体过程如图 3 所示. 求出轮廓中心点, 利用标定时计算出的内外参数矩阵,通过式(3)、 (4)和(6)求出目标物体的 3D 坐标.
图 3 为果蔬识别过程图, 其主要包括未经处理的原图、 深度分割后的图像、 HSV 颜色空间二值化图及经过形状特征识别后的轮廓图.</p>

<hr />

<h2 id="基于-kinect-视觉系统的西红柿自动识别与定位-董建民">基于 Kinect 视觉系统的西红柿自动识别与定位[董建民]</h2>

<blockquote>
<p>传 统 的 西 红 柿 采 摘 机 器 人 的 视 觉 系 统 都 是 采 用 双 目 摄 像 头 , 使 用 时 需 要 进 行 摄 像 头 参 数 标 定 , 使 用 过 程 复 杂 。 本 文 提 出 用Kinect 代 替 传 统 的 双 目 摄 像 头 , 获 得 RGB 彩 色 图 像 和 目 标 深 度 图 像 , 对 彩 色 图 像 分 别 在 HSI 和 Lab 颜 色 空 间 进 行 分 通 道 图 像 分割 , 再 将 两 种 结 果 进 行 融 合 后 去 除 背 景 噪 声 。 对 采 集 的 样 本 图 像 进 行 分 割 实 验 , 结 果 表 明 此 种 方 法 分 割 效 果 良 好 。 对 深 度 图 像 进 行三 维 重 建 获 得 西 红 柿 质 心 的 三 维 立 体 坐 标 值 , 实 验 表 明 目 标 定 位 准 确 度 高 , 该 空 间 坐 标 值 可 用 于 指 导 真 空 吸 盘 机 械 手 进 行 目 标 西红柿的自动采摘 。</p>
</blockquote>

<h3 id="研究情况-1">研究情况</h3>

<ul>
<li>目前对西红柿识别的方法有很多 , 例 色空间可以通用。如将图像进行灰度变换 , 采用拟合曲线对西红柿的分割传统的分割方法是在 RBG 颜色空间, 将图像分成; 由 RGB 颜色空间转到 HSI 颜色空间, 采用遗 R 、 G 、 B 三个单通道的灰度图像, 然后对 R 通道的图传算法训练多层前馈神经网络实现西红柿成熟度的 像进行分割。 一般是采用多幅图像统计的方法, 得到自动判别 最佳阈值然后进行阈值分割, 实验结果如图 1 所示。[1][2]; 根据颜色特征利用阈值自动设定的方法对西红柿进行分割[2]。 这些方法都能从背景中将西红柿分割出来 , 但这些方法都有一定的不足 , 成功 率 较 低 。</li>
<li>传统的果实定位采用双目立体视觉技术 ,缺 点 是 要 进 行 复 杂 的 摄像机标定 , 使用不方便 ,计 算 速 度 较 慢 。</li>
</ul>

<h3 id="本文核心-1">本文核心</h3>

<p>本 文 采 用 分 别 在 HSI 和 Lab 颜 色 空 间 进 行图像分割 , 然后将两个结果进行融合 , 再去除背景噪声的分割方法 , 该方法可以提高西红柿分割的准确性。本 文 利 用 Kinect 代 替 双 目 摄 像 头 ,无需进行参数标定可直接获得深度图像信息 , 实验表明此种方法可降低成本 , 提高定位速度和精度。</p>

<h3 id="传统做法">传统做法</h3>

<p>传统的分割方法是在 RBG 颜色空间, 将图像分成 R 、 G 、 B 三个单通道的灰度图像, 然后对 R 通道的图 像进行分割。 一般是采用多幅图像统计的方法, 得到最佳阈值然后进行阈值分割,
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 16:31:46屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure></p>

<p>从图 1 所示的分割结果可以看出, 背景 噪声不能完全去除, 而且分割结果受光照的影响较大, 西红柿上有明显的亮斑。 RGB 颜色空间适合于显示, 不适合 于图像分割和分析, 因为 R 、 G 、 B 的 3 个分量 是高度 相关的, RGB 色彩空间容易受到光照的影响, 即只要 亮度改变, 3 个分量都会相应改变, 很难将图像中目标与背景区分。</p>

<p>利 用 线 性 或 非 线 性 变 换 , 则 可 以 由 RGB 颜 色 空间推导出其他的颜色特征空间 。 线性变换空间主要有 YIQ 、 YUV 、 I <sub>1</sub>  I <sub>2</sub>  I <sub>3</sub> [ 4]。 由于是线性变换 , 所以计算 量 小 , 并 且 部 分 消 除 了 RGB 的 相 关 性 。 非 线 性 变换 空 间 主 要 有 HSI 、 Lab 、 Luv 、 NRGB 等 , 其 中 HSI与人眼看物体时的感知特性类似 。 目前虽有多种颜色空间用于彩色图像处理 , 但由于无论哪一种都无法替代其他的颜色空间而适用于所有彩色图像处, 故选择最佳的颜色空间是彩色图像分割的一个难题[10]。</p>

<h3 id="hsi-颜色特征分析与提取">HSI 颜色特征分析与提取</h3>

<p>HSI 色 彩 空 间 直 接 采 用 彩 色 特 性 意 义 上 的 3 个量 : H 代表 色调 ; S 代 表 饱 和 度 ; I 代 表 亮 度 或 透 明度 。 因色调与高亮 、 阴影无关 , 色调对区分不同颜色 的 物 体 非 常 有 效 。 从 RGB 到 HSI 颜 色 空 间 转 换 的公式为 :</p>

<p><figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 16:44:21屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure></p>

<p>在 HSI 颜 色 空 间 中 H 、 S 、 I 的 3 个 分 量 相 互 独 立 ,可分别对这 3 个量进行控制。 西红柿表面光滑, 在光照变化的情况下影响图像的提取, 所以处理时只考虑 H 分量, 这样就避免了光照的影响, 使得图像处理针 对性更强。 具体做法是只对 H 分量进行阈值分割。 阈 值分割的方法有很多, 如大津法、 双峰法、 迭代法、最大熵法、 Otsu 法等。 本文提出基于门限改进的 Otsu法完成对 H 分量的图像分割。</p>

<h4 id="改进otsu法">改进Otsu法</h4>

<p>改进的思路就是结合迭代法和 Otsu 法, 根据图像先确定一个初始阈值 T 1 , 然后利用 Otsu 法自动获取最佳阈值 T :
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 16:49:50屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure></p>

<p>式中:</p>

<ul>
<li><p>p 1 ( t )、 p 2 ( t )———被阈值 t 分割后目标和背景 2 个区域的概率;</p></li>

<li><p>μ 1 ( t )、 μ 2 ( t )——被阈值 t 分割后目标和背景 2 个区域的平均灰度值;</p></li>

<li><p>σ 2 ( t )——目 标 和 背 景 类 间 方 差 值 , 当 σ 2 ( t )最 大时, t 即为分割的最佳阈值。</p></li>
</ul>

<p>将获得的两 个阈值 进 行 比 较 , 如 果 T 1 ≥T , 则 最佳阈值为 T , 如果 T 1 ≤T , 则最佳阈值为 T 1 。 本例初始阈值 T 1 =115 。 HIS 颜色空间分割结果如图 2 所示。
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 16:53:16屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure></p>

<h3 id="lab-色彩空间图像分割">Lab 色彩空间图像分割</h3>

<p>Lab 色 彩 空 间 是 根 据 色 度 和 亮 度 组 成 的 3 维 空 间图, 它适用于一切光源色或物体色的表示与计算。 其中 L 表示心理明度, a 、 b 为心理色度。 在 Lab 色彩空间坐标中, +a 表示红色, -a 表示绿色, +b 表示黄色, -b在 HSI 颜 色 空 间 中 H 、 S 、 I 的 3 个 分 量 相 互 独 立 ,可分别对这 3 个量进行控制。 西红柿表面光滑, 在光表示蓝色, 颜色的明度由 L 的百分数来表示, 其取值从 0~100 。
通过西红柿的颜色特征, 我们很明显得出成熟的西 红 柿 为 +a ( 红 色 ) , 未 成 熟 的 西 红 柿 及 枝 干 和 叶 子为 -a ( 绿色 ) 。 因此选择 Lab 色彩空间来对成熟西红柿进行分割是非常合适的。
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 17:00:43屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure></p>

<p>将原始图像 由 RGB 颜色空间 转换到 Lab 颜色 空间后, 将图像的 L 通道、 a 通道、 b 通道的图像分离出来,得到 3 个独立的灰度图像,所以我们只需对 a 通道的图像进行处理从而完成对成熟西红柿的分割 。 基于灰度图像的分割方法很多, 本文采用 K 均值聚类算法它通过迭代地执行分类算法来提取各类的特征值。 最终的分割结果如图 3 所示。
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="../../../pic/lunwen/2017-01-05 17:05:00屏幕截图.png" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure></p>

<p>将在 HSI 与 Lab 颜色空间的到的两个分割结果进行融合处理。 图像融合方法有多种, 如颜色过渡法、 小波融合法和多分辨率样条法等。 虽然这些算法的效果较好, 但计算量较大。 本文采用简单快速的加权平均算法。 该算法的主要思想是: 图像重叠区域中像素点的灰度值 P 由两幅图像 中对应点的 灰度值 P H 和 P a 加 权平均得到, 即:</p>

<p>P=K×P<sub>H</sub> + ( 1-K) ×P<sub>a</sub>                                   (3)</p>

<p>式 中 : K —可 调 因 子 。
通 常 情 况 下 0&lt;K&lt;1 , 即 在 重 叠 区 域 中 , 沿 左 图像 向 右 图 像 的 方 向 , K 由 1 渐 变 为 0 , 从 而 实 现 重 叠区域的平滑拼接 , 最后对融合得到的分割结果去除背景噪声 。 本文采取的方法是 : 对于联通区域较小的背景噪声采取形态学运算的方法去除 ; 对于连通区域面积较大的背景噪声采取设定阈值进行面积判断 , 比如小于西红柿面积多少的连通区域认为是噪声 , 此种去噪声方法对于遮挡较少的情况具有很好的 鲁 棒 性 。</p>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>Fengcai.Sun </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://ottsion.github.io/2017/2017-01-05-lunwen1/>https://ottsion.github.io/2017/2017-01-05-lunwen1/</span>
            </p>
            
             
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="https://ottsion.github.io/tags/%E8%AE%BA%E6%96%87/">
                    #论文</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="https://ottsion.github.io">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://ottsion.github.io/2017/2017-01-05-lunwen2/" class="prev" rel="prev" title="基于 Kinect 视觉系统的西红柿自动识别与定位[董建民]"><i class="iconfont icon-left"></i>&nbsp;基于 Kinect 视觉系统的西红柿自动识别与定位[董建民]</a>
         
        
        <a href="https://ottsion.github.io/2017/2017-01-05-eigen-use-2/" class="next" rel="next" title="Eigen矩阵库——初步用法（二）">Eigen矩阵库——初步用法（二）&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2019 - 2020</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="https://ottsion.github.io">Fengcai.Sun</a> | </span> 
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
    </div>
</footer>












    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  



     </div>
  </body>
</html>
